## General CNN Architectures & Understanding & Interpretation

### Convolutional Neural Networks
&nbsp;&nbsp;&nbsp;&nbsp;**Review papers & technical reports**
1. Recent Advances in Convolutional Neural Networks, *Jiuxiang Gu et al, Pattern Recognition* *2017*. [pdf](https://reader.elsevier.com/reader/sd/pii/S0031320317304120?token=106FDF6803F64264A80962850E808CE382F6ACA19A91E8F2A72B3407A083A6C86149FD1B652AB48367BA2EEAB64D3564)
1. A practical theory for designing very deep convolutional neural networks, *Xudong Cao et al, Arxiv* *2015*. [pdf](https://pdfs.semanticscholar.org/7922/2fad9f671be142bd7e42cd785a2cb06a1d30.pdf?_ga=2.116614400.788554961.1558921438-980990197.1558921438)
1. Benchmark Analysis of Representative Deep Neural Network Architectures, *SIMONE BIANCO et al, IEEE Access* *2018*. [pdf](https://arxiv.org/pdf/1810.00736.pdf) 
<img src="https://github.com/Zakiyi/Paper-lists/blob/master/figures/CNN%20benchmark.png" alt="drawing" width="600"/>

&nbsp;&nbsp;&nbsp;&nbsp;**2012-2016**
1. ImageNet Classification with Deep Convolutional Neural Networks, *Alex Krizhevsky et al, NIPS* 2012. [pdf](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)
1. PCANet: A Simple Deep Learning Baseline for Image Classification? *Tsung-Han Chan et al, IEEE TIP* 2013. [pdf](https://arxiv.org/pdf/1404.3606.pdf)
1. Visualizing and Understanding Convolutional Networks, *Matthew D. Zeiler et al, ECCV* 2014. [pdf](https://arxiv.org/pdf/1311.2901.pdf)
1. Network In Network, *Min Lin et al, ICLR* 2014. [pdf](https://arxiv.org/pdf/1312.4400.pdf)
1. Deeply-Supervised Nets, *Chen-Yu Lee et al, AISTATS* 2015. [pdf](https://chl260.github.io/PDF/Lee_AISTATS15.pdf)
1. Highway Networks, *R. K. Srivastava et al ICML* 2015. [pdf](https://arxiv.org/pdf/1505.00387.pdf)
1. Very Deep Convolutional Networks For Large-Scale Image Recognition, *Karen Simonyan et al, ICLR* 2015. [pdf](https://arxiv.org/pdf/1409.1556.pdf)
1. Going Deeper with Convolutions (**Inception v1**), *Christian Szegedy et al, CVPR* 2015. [pdf](https://www.cs.unc.edu/~wliu/papers/GoogLeNet.pdf)
1. Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift (**Inception v2/BN inception**), *Sergey Ioffe et al,  ICML* 2015. [pdf](http://proceedings.mlr.press/v37/ioffe15.pdf) 
1. Rethinking the Inception Architecture for Computer Vision (**Inception v3**), *Christian Szegedy et al, CVPR* 2016. [pdf](https://arxiv.org/pdf/1512.00567.pdf)
1. Deep Residual Learning for Image Recognition, *Kaiming He et al, CVPR* 2016. [pdf](https://arxiv.org/pdf/1512.03385.pdf)
1. Wide Residual Networks, *Sergey Zagoruyko et al, BMVC*. [pdf](https://arxiv.org/pdf/1603.09382v3.pdf)
1. Deep pyramidal residual networks, *Dongyoon Han et al, CoRR* 2016. [pdf](https://arxiv.org/pdf/1610.02915.pdf), [related blog](http://torch.ch/blog/2016/02/04/resnets.html) &#x1F33E;&#x1F33E;
1. Identity Mappings in Deep Residual Networks, *Kaiming He et al, ECCV* 2016. [pdf](https://arxiv.org/pdf/1603.05027v3.pdf)
1. Deep Networks with Stochastic Depth, *Gao Huang et al, ECCV*. [pdf](https://arxiv.org/pdf/1603.09382v3.pdf) 
1. Understanding and Improving Convolutional Neural Networks via Concatenated Rectified Linear Units, *Wenling Shang et al, ICML.* [pdf](https://arxiv.org/pdf/1603.05201.pdf)

&nbsp;&nbsp;&nbsp;&nbsp;**2017**
1. Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning (**Inception v4**), *Christian Szegedy et al, AAAI* 2017. [pdf](https://arxiv.org/pdf/1602.07261.pdf)
1. Xception: Deep Learning with Depthwise Separable Convolutions, *Franc¸ois Chollet et al, CVPR*. [pdf](https://arxiv.org/pdf/1610.02357.pdf)
1. Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning, *Christian Szegedy et al, AAAI*. [pdf](https://arxiv.org/pdf/1602.07261.pdf)  [Review article of the Inception series](https://towardsdatascience.com/a-simple-guide-to-the-versions-of-the-inception-network-7fc52b863202)  
1. Aggregated Residual Transformations for Deep Neural Networks, *Saining Xie et al, CVPR*. [pdf](https://arxiv.org/pdf/1611.05431.pdf)
1. Densely Connected Convolutional Networks, *Gao Huang et al, CVPR*. [pdf](https://arxiv.org/pdf/1608.06993.pdf)
1. Deformable Convolutional Networks, *Jifeng Dai et al, ICCV*. [pdf](https://arxiv.org/pdf/1703.06211.pdf)
1. Dynamic Routing Between Capsules, *Sara Sabour et al, NIPS*. [pdf](https://papers.nips.cc/paper/6975-dynamic-routing-between-capsules.pdf)
1. Dilated Residual Networks, *Fisher Yu et al, CVPR*. [pdf](https://arxiv.org/pdf/1705.09914.pdf) &#x1F33E;&#x1F33E;
1. Dual Path Networks， *Yunpeng Chen et al, NIPS* . [pdf](https://papers.nips.cc/paper/7033-dual-path-networks.pdf)

&nbsp;&nbsp;&nbsp;&nbsp;**2018**
1. CBAM: Convolutional Block Attention Module, *Sanghyun Woo et al, ECCV*. [pdf](https://eccv2018.org/openaccess/content_ECCV_2018/papers/Sanghyun_Woo_Convolutional_Block_Attention_ECCV_2018_paper.pdf)
1. Deformable ConvNets v2: More Deformable, Better Results, *Xizhou Zhu et al, Arxiv*. [pdf](https://arxiv.org/pdf/1811.11168.pdf)
1. Squeeze-and-Excitation Networks, *Jie Hu et al, CVPR*. [journal pdf](https://arxiv.org/pdf/1709.01507.pdf) [conf pdf](http://openaccess.thecvf.com/content_cvpr_2018/papers/Hu_Squeeze-and-Excitation_Networks_CVPR_2018_paper.pdf) &#x1F33E;&#x1F33E;&#x1F340;
1. CondenseNet: An Efficient DenseNet using Learned Group Convolutions, *Gao Huang et al, CVPR*. [pdf](https://arxiv.org/pdf/1711.09224.pdf)
1. Learning Transferable Architectures for Scalable Image Recognition (**NASNet**), *Barret Zoph et al, CVPR*. [pdf](https://arxiv.org/pdf/1707.07012.pdf)
1. Beyod Finite Layer Neural Networks Bridging Deep Architecture and Numerical Differential Equations, *Yiping Lu et al, ICML*. [pdf](https://arxiv.org/pdf/1710.10121v2.pdf)
1. ResNet Sparsifier: Learning Strict Identity Mappings in Deep Residual Networks, *Xin Yu et al, CVPR*. [pdf](https://arxiv.org/pdf/1804.01661v4.pdf)
1. Competitive Inner-Imaging Squeeze and Excitation for Residual Network, *Yang Hu et al, Arxiv.* [pdf](https://arxiv.org/pdf/1807.08920.pdf)
1. Convolutional Neural Networks with Alternately Updated Clique, *Yibo Yang et al, CVPR.* [pdf](https://arxiv.org/pdf/1802.10419.pdf)
1. BAM: Bottleneck Attention Module, *Jongchan Park et al, Arxiv.* [pdf](https://arxiv.org/pdf/1807.06514.pdf)
1. Dynamic Sampling Convolutional Neural Networks, *Jialin Wu et al, ECCV.* [pdf](http://openaccess.thecvf.com/content_ECCV_2018/papers/Jialin_Wu_Dynamic_Sampling_Convolutional_ECCV_2018_paper.pdf)

&nbsp;&nbsp;&nbsp;&nbsp;**2019**
1. Selective Kernel Networks, *Xiang Li et al, CVPR*. [pdf](https://arxiv.org/pdf/1903.06586.pdf)
1. Res2Net: A New Multi-scale Backbone Architecture, *Shang-Hua Gao et al, Arxiv*. [pdf](https://arxiv.org/pdf/1904.01169.pdf)
1. Exploring Randomly Wired Neural Networks for Image Recognition, *Saining Xie et al, Arxiv*. [pdf](https://arxiv.org/pdf/1904.01569.pdf)
1. Deep Layer Aggregation, *Fisher Yu et al, Arxiv.* [pdf](https://arxiv.org/pdf/1707.06484.pdf)
1. Convolutional Neural Networks Combined with Runge-Kutta Methods, *Mai Zhu et al, ICLR.* [pdf](https://arxiv.org/pdf/1802.08831.pdf)
1. Making Convolutional Networks Shift-Invariant Again, *Richard Zhang, Arxiv.* [pdf](https://arxiv.org/pdf/1904.11486.pdf)
1. Spatial Group-wise Enhance: Improving Semantic Feature Learning in Convolutional Networks, *Xiang Li et al, Arxiv.* [pdf](https://arxiv.org/pdf/1905.09646.pdf)
1. SLIMMABLE NEURAL NETWORKS, *Jiahui Yu et al, ICLR.* [pdf](2019)

&nbsp;&nbsp;&nbsp;&nbsp;**2020**
1.
1. Designing Network Design Spaces (**RegNet**), *Ilija Radosavovic et al, Arxiv.* [pdf](https://arxiv.org/pdf/2003.13678.pdf)
1. Neural Architecture Design for GPU-Efficient Networks, *Ming Lin et al, Arxiv.* [pdf](https://arxiv.org/pdf/2006.14090.pdf)

## Interpretation & Understanding

&nbsp;&nbsp;&nbsp;&nbsp;**Inspiring articles & reports**
1. Deep learning and shallow data, [Piekniewski's blog](https://blog.piekniewski.info/2019/04/07/deep-learning-and-shallow-data/)

&nbsp;&nbsp;&nbsp;&nbsp;**Publications**
1. Residual Networks Behave Like Ensembles of Relatively Shallow Networks, *Andreas Veit et al, NIPS* **2016**. [pdf](https://arxiv.org/pdf/1605.06431v2.pdf)
1. Interpreting Deep Visual Representations via Network Dissection, *Bolei Zhou et al, TPAMI* **2018**. [pdf](https://arxiv.org/pdf/1711.05611.pdf)
1. Similarity of Neural Network Representations Revisited, *Simon Kornblith et al, Arxiv* ***2019***. [pdf](https://arxiv.org/pdf/1905.00414.pdf)
1. Understanding the Effective Receptive Field in Deep Convolutional Neural Networks, *Wenjie Luo et al, Arxiv* ***2017***.[pdf](https://arxiv.org/pdf/1701.04128.pdf)
1. What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision? *Alex Kendall et al, NIPS*. [pdf](https://arxiv.org/pdf/1703.04977.pdf)
1. ImageNet-Trained CNNs are Biased Towards Texture; Increasing Shape Bias Improves Accuracy and Robustness, *Robert Geirhos et al, ICLR.* [pdf](https://arxiv.org/pdf/1811.12231.pdf)
1. Revealing Fine Structures of the Retinal Receptive Field by Deep Learning Networks, *Qi Yan et al, Arxiv.* [pdf](https://arxiv.org/pdf/1811.02290v1.pdf)
1. Are All Layers Created Equal? *Chiyuan Zhang et al, Arxiv.* [pdf](https://arxiv.org/pdf/1902.01996.pdf)

